{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from numpy.linalg import matrix_power\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS0 Empirical IO: Numerical Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Logit Inclusive Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Convexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logit inclusive value is the log of the denominator of a logit probability of choice. It is as follows:\n",
    "\n",
    "$$\n",
    "IV = \\log \\sum_{i=0}^N \\exp(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $x_0 = 0$. Then, $IV(x_1, ... , x_n) = \\log \\sum_{i=1}^N (1+\\exp(x_i))$. We want to show that this function is convex everywhere. The second derivative of this function is:\n",
    "$$\n",
    "\\frac{\\partial^2}{\\partial x_i^2} \\log\\left(N + \\sum_{j=1}^N \\exp(x_j)\\right) = \\exp(2x_i) \\left( \\frac{S - 1}{S^2} \\right)\n",
    " \\\\\n",
    "S = N + \\sum_{j=1}^N \\exp(x_j).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is indeed positive. Therefore, this function is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Large $x_i$ problem\n",
    "\n",
    "For large values of $x_i$, we cannot manage to find the exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resolve this issue, we now that, given $m = \\max_i x_i$:\n",
    "\n",
    "$$\n",
    "IV = \\log \\sum_{i=0}^N \\exp(x_i) = \\log \\left(\\exp(m)\\sum_{i=0}^N \\exp(x_i - m)\\right)\n",
    "$$\n",
    "Therefore, we have:\n",
    "\n",
    "$$\n",
    "IV = m + \\log \\sum_{i=0}^N \\exp(x_i - m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_IV(x):\n",
    "    m = np.max(x)\n",
    "    IV = m + np.log(np.sum(np.exp(x - m)))\n",
    "    return IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the above method, IV is: 800.3132616875182\n",
      "Using the naive method, IV is: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_24228\\1108397953.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  IV_unstable = np.log(np.sum(np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "x = np.array([300, 400, 500, 750, 799, 800])\n",
    "IV_stable = solve_IV(x)\n",
    "print(\"Using the above method, IV is:\", IV_stable)\n",
    "IV_unstable = np.log(np.sum(np.exp(x)))\n",
    "print(\"Using the naive method, IV is:\", IV_unstable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. logsumexp function in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scipy's logsumexp, IV is: 800.3132616875182\n"
     ]
    }
   ],
   "source": [
    "IV_stable_python = logsumexp(x)\n",
    "print(\"Using scipy's logsumexp, IV is:\", IV_stable_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function in python uses the same method as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the goal is to write a function to solve for the ergodic distribution of a markov process, given its transition matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this properly, we can use the idea of eigenvalues and eigen vectors. We know that, the ergodic distribution is the fixed point of $\\pi P$. Therefore:\n",
    "\n",
    "$$\n",
    "\\pi = \\pi P \\rightarrow (P' - I)\\pi' = 0\n",
    "$$\n",
    "\n",
    "So, the ergodic distribution is the normalized eigenvector (should be added to one) corresponding to eigenvalue of 1 for matrix $P'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ergodic_distribution(P):\n",
    "    # Step 1: Compute the eigenvalues and eigenvectors of the transpose of P\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "    \n",
    "    # Step 2: Find the eigenvector corresponding to the eigenvalue 1\n",
    "    # We assume there is exactly one eigenvalue that is 1 for a valid transition matrix\n",
    "    eigenvector = eigenvectors[:, np.isclose(eigenvalues, 1)]\n",
    "    \n",
    "    # Step 3: Normalize the eigenvector\n",
    "    steady_state = eigenvector[:, 0]  # Extract the eigenvector (as it's returned in a 2D array)\n",
    "    steady_state = steady_state / np.sum(steady_state)\n",
    "    \n",
    "    # Ensure the result is real (numerical computations may result in a complex vector with very small imaginary parts)\n",
    "    steady_state = steady_state.real\n",
    "    \n",
    "    return steady_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steady state distribution is: [0.31  0.241 0.448]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[0.2, 0.4, 0.4],\n",
    "              [0.1, 0.3, 0.6],\n",
    "              [0.5, 0.1, 0.4]])\n",
    "steady_state = ergodic_distribution(P)\n",
    "print(\"The steady state distribution is:\", steady_state.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice that:\n",
    "$$\n",
    "\\pi_t = \\pi_0 P^t\n",
    "$$\n",
    "So, to find the ergodic distribution, we can set $\\pi_0 = [1, 0, ..., 0]$ and find $\\pi_t$ for large values of $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ergodic distribution is: [0.31  0.241 0.448]\n"
     ]
    }
   ],
   "source": [
    "pi_0 = np.array([1, 0, 0])\n",
    "ergodic = pi_0 @ matrix_power(P, 100)\n",
    "print(\"The ergodic distribution is:\", ergodic.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that these are the same results. When reached to the ergodic distribution, the distribution of transitioning from each alternative is the same and equal to the ergodic distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Numerical Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the goal is to solve for the logit choice probability by numerical integration. \n",
    "\n",
    "$$\n",
    "p(X, \\theta)=\\int_{-\\infty}^{\\infty} \\frac{\\exp \\left(\\beta_i X\\right)}{1+\\exp \\left(\\beta_i X\\right)} f\\left(\\beta_i \\mid \\theta\\right) \\partial \\beta_i \\,\\, ,\\,\\, f\\sim N(0.5,2) \\,\\, ,\\,\\, X = 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the quad function in python, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The integral is: 0.5559391628434652\n"
     ]
    }
   ],
   "source": [
    "X = 0.5\n",
    "mean = 0.5\n",
    "sigma = np.sqrt(2)\n",
    "integral = quad(lambda beta: np.exp(beta*X)/(1 + np.exp(beta*X))\n",
    "                * 1/(np.sqrt(2*np.pi) * sigma) * \n",
    "                np.exp(-((beta - mean)/sigma)**2/2), -100, 100, epsabs=1e-14)[0]\n",
    "print(\"The integral is:\", integral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
