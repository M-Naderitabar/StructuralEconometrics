{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels linearmodels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'C:\\\\Users\\\\moham\\\\My Drive\\\\Projects\\\\Structural Econometrics Projects\\\\Topics in Advanced Econometrics\\\\2- Logit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_data = pd.read_csv(address + '\\\\commute_multinomial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will do some likelihood ratio tests. So, I will write a function here to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio_test(ll_U, ll_R, df):\n",
    "    test_stat = 2 * (ll_U - ll_R)\n",
    "    p_value = 1 - chi2.cdf(test_stat, df)\n",
    "    \n",
    "    if p_value < 0.01:\n",
    "        result = f'Reject the null hypothesis (p-value: {p_value:.4f})'\n",
    "    else:\n",
    "        result = f'Fail to reject the null hypothesis (p-value: {p_value:.4f})'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. \n",
    "Again, the problem is for commute. Each agent has four alternatives to choose from. The utility is as follows:\n",
    "\n",
    "$$\n",
    "V_{nj} = \\beta C_{nj} + \\gamma T_{nj}\n",
    "$$\n",
    "Therefore, given a multinomial logit model, the log-likelihood function is as follows:\n",
    "$$\n",
    "\\ln L(\\theta \\mid y, \\boldsymbol{X})=\\sum_{n=1}^N \\sum_{i=1}^J y_{n i} \\ln \\left[\\frac{e^{\\beta C_{n,i} + \\gamma T_{n,i}}}{\\sum_j e^{\\beta C_{n,j} + \\gamma T_{n,j}}}\\right]\n",
    "$$\n",
    "\n",
    "So, we will define a function that, given the parameters and data as inputs, and solve for the loglikelihood function. But, first, we need to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of modes\n",
    "modes = ['bike', 'bus', 'car', 'walk']\n",
    "\n",
    "# Reshape the DataFrame\n",
    "rows = []\n",
    "for index, row in commute_data.iterrows():\n",
    "    for mode in modes:\n",
    "        rows.append({\n",
    "            'id': row['id'],\n",
    "            'mode': mode,\n",
    "            'time': row[f'time.{mode}'],\n",
    "            'cost': row[f'cost.{mode}'],\n",
    "            'choice': 1 if row['mode'] == mode else 0\n",
    "        })\n",
    "\n",
    "commute_long = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mode</th>\n",
       "      <th>time</th>\n",
       "      <th>cost</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bike</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bus</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>walk</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mode  time  cost  choice\n",
       "0   1  bike    20  0.00       0\n",
       "1   1   bus    20  0.00       1\n",
       "2   1   car    16  0.82       0\n",
       "3   1  walk    55  0.00       0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commute_long.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(params, data):\n",
    "    # Create a copy of the input DataFrame to avoid modifying the original one\n",
    "    df = data.copy()\n",
    "    # Independent variables as a NumPy array\n",
    "    X = df[['time', 'cost']]\n",
    "    # Calculating the exponential utility\n",
    "    df['exp_Util'] = np.exp(np.dot(X, params))\n",
    "    # Summing exp_Util for each id\n",
    "    df['sum_exp_Util'] = df.groupby('id')['exp_Util'].transform('sum')\n",
    "    # Probability calculation\n",
    "    df['prob'] = df['exp_Util'] / df['sum_exp_Util']\n",
    "    # Calculating the log-likelihood\n",
    "    loglikelihood_value = np.sum(df['choice'] * np.log(df['prob']))\n",
    "    # Return negative log-likelihood (for minimization)\n",
    "    return -loglikelihood_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will find the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1219.844944\n",
      "         Iterations: 11\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "initial_params = np.zeros(2)\n",
    "result = minimize(loglikelihood, \n",
    "                  initial_params, \n",
    "                  args=(commute_long[['id', 'choice', 'time', 'cost']],), \n",
    "                  method='BFGS', \n",
    "                  options={'disp': True})\n",
    "parameters = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from MLE, we remember that the asymptotic distribution is as follows:\n",
    "\n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\theta}} \\stackrel{a}{\\sim} \\mathcal{N}\\left(\\boldsymbol{\\theta}_0, I\\left(\\boldsymbol{\\theta}_0\\right)^{-1}\\right) \\,\\, ,\\,\\, I\\left(\\boldsymbol{\\theta}_0\\right)=-E_0\\left[\\frac{\\partial^2 \\ln L\\left(\\boldsymbol{\\theta}_0\\right)}{\\partial \\boldsymbol{\\theta}_0 \\partial \\boldsymbol{\\theta}_0^{\\prime}}\\right]\n",
    "$$\n",
    "Then:\n",
    "$$\n",
    "\\widehat{\\operatorname{Var}}(\\widehat{\\boldsymbol{\\theta}})=\\left\\{-\\left.\\frac{\\partial^2 \\ln L(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^{\\prime}}\\right|_{\\boldsymbol{\\theta}=\\widehat{\\boldsymbol{\\theta}}}\\right\\}^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter  Coefficient  Standard Error  Z-statistic  P-value\n",
      "     Time       -0.126           0.009      -14.191      0.0\n",
      "     Cost       -1.002           0.171       -5.854      0.0\n"
     ]
    }
   ],
   "source": [
    "std = np.sqrt(result.hess_inv.diagonal())\n",
    "z_stat = parameters / std\n",
    "p_values = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "summary_table = pd.DataFrame({\n",
    "    'Parameter': ['Time', 'Cost'],\n",
    "    'Coefficient': parameters,\n",
    "    'Standard Error': std,\n",
    "    'Z-statistic': z_stat,\n",
    "    'P-value': p_values\n",
    "})\n",
    "print(summary_table.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. \n",
    "\n",
    "Now, we change the model to the following:\n",
    "\n",
    "$$\n",
    "V_{nj} = \\alpha_{j} + \\beta C_{nj} + \\gamma T_{nj}\n",
    "$$\n",
    "\n",
    "So, we have alternative specific intercepts. Here, the parameter space is $\\{\\alpha_{bus},\\alpha_{car}, \\alpha_{walk},\\beta, \\gamma\\}$. So, we need to modify the model to add dummies for alternatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of modes\n",
    "modes = ['bike', 'bus', 'car', 'walk']\n",
    "\n",
    "# Reshape the DataFrame\n",
    "rows = []\n",
    "for index, row in commute_data.iterrows():\n",
    "    for mode in modes:\n",
    "        rows.append({\n",
    "            'id': row['id'],\n",
    "            'mode': mode,\n",
    "            'time': row[f'time.{mode}'],\n",
    "            'cost': row[f'cost.{mode}'],\n",
    "            'choice': 1 if row['mode'] == mode else 0\n",
    "        })\n",
    "\n",
    "commute_long_b = pd.DataFrame(rows)\n",
    "\n",
    "for mode in modes:\n",
    "    commute_long_b[f'dummy_{mode}'] = (commute_long_b['mode'] == mode).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mode</th>\n",
       "      <th>time</th>\n",
       "      <th>cost</th>\n",
       "      <th>choice</th>\n",
       "      <th>dummy_bike</th>\n",
       "      <th>dummy_bus</th>\n",
       "      <th>dummy_car</th>\n",
       "      <th>dummy_walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bike</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bus</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>walk</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mode  time  cost  choice  dummy_bike  dummy_bus  dummy_car  dummy_walk\n",
       "0   1  bike    20  0.00       0           1          0          0           0\n",
       "1   1   bus    20  0.00       1           0          1          0           0\n",
       "2   1   car    16  0.82       0           0          0          1           0\n",
       "3   1  walk    55  0.00       0           0          0          0           1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commute_long_b.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_b(params, data):\n",
    "    # Create a copy of the input DataFrame to avoid modifying the original one\n",
    "    df = data.copy()\n",
    "    X = df[['dummy_bike', 'dummy_bus', 'dummy_car',\n",
    "            'dummy_walk', 'time', 'cost']]\n",
    "    N = X.shape[1]\n",
    "    n = len(params)\n",
    "    for i in range(N - n):\n",
    "        params = np.insert(params, 0, 0)\n",
    "    # Calculating the exponential utility\n",
    "    df['exp_Util'] = np.exp(np.dot(X, params))\n",
    "    # Summing exp_Util for each id\n",
    "    df['sum_exp_Util'] = df.groupby('id')['exp_Util'].transform('sum')\n",
    "    # Probability calculation\n",
    "    df['prob'] = df['exp_Util'] / df['sum_exp_Util']\n",
    "    # Calculating the log-likelihood\n",
    "    loglikelihood_value = np.sum(df['choice'] * np.log(df['prob']))\n",
    "    # Return negative log-likelihood (for minimization)\n",
    "    return -loglikelihood_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params_b = np.zeros(5) # alpha_bike, alpha_bus, alpha_car, alpha_walk, beta, gamma\n",
    "result = minimize(loglikelihood_b, \n",
    "                  initial_params_b, \n",
    "                  args=(commute_long_b[['dummy_bike', 'dummy_bus', 'dummy_car', 'dummy_walk',\n",
    "                                      'id', 'choice', 'time', 'cost']],),\n",
    "                  method='BFGS', \n",
    "                  options={'disp': False})\n",
    "parameters = result.x\n",
    "ll_U = -result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Parameters  Coefficient  Standard Error  Z-statistic  P-value\n",
      "  Bus_intecept        1.760           0.253        6.958    0.000\n",
      " Car_intercept        2.925           0.202       14.511    0.000\n",
      "Walk_intercept        3.172           0.735        4.316    0.000\n",
      "          Time       -0.296           0.085       -3.469    0.001\n",
      "          Cost       -6.055           1.027       -5.895    0.000\n"
     ]
    }
   ],
   "source": [
    "std = np.sqrt(result.hess_inv.diagonal())\n",
    "z_stat = parameters / std\n",
    "p_values = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "summary_table_b = pd.DataFrame({\n",
    "    'Parameters': ['Bus_intecept', 'Car_intercept', 'Walk_intercept', 'Time', 'Cost'],\n",
    "    'Coefficient': parameters,\n",
    "    'Standard Error': std,\n",
    "    'Z-statistic': z_stat,\n",
    "    'P-value': p_values\n",
    "})\n",
    "print(summary_table_b.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, as the intercepts are positive, ceteris paribus, students prefer all three alternatives to biking (as it is the base case with zero intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a likelihood ratio test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to test the following:\n",
    "\n",
    "$$\n",
    "H_0: \\alpha_{bus} = \\alpha_{car} = \\alpha_{walk} = 0\n",
    "$$\n",
    "\n",
    "So, it is done as follows:\n",
    "\n",
    "$$\n",
    "-2 \\ln \\lambda \\sim \\chi^2(J) \\,\\, \\,\\, ,\\,\\,\\,\\, -2 \\ln \\lambda=2\\left(\\ln L\\left(\\hat{\\boldsymbol{\\theta}}_U\\right)-\\ln L\\left(\\widehat{\\boldsymbol{\\theta}}_R\\right)\\right)\n",
    "$$\n",
    "\n",
    "with $J = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1219.844944\n",
      "         Iterations: 11\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "initial_params_restricted = np.zeros(2) #beta, gamma\n",
    "result = minimize(loglikelihood_b,\n",
    "                  initial_params_restricted, \n",
    "                  args=(commute_long_b[['dummy_bike', 'dummy_bus', 'dummy_car', 'dummy_walk',\n",
    "                                      'id', 'choice', 'time', 'cost']],),\n",
    "                  method='BFGS', \n",
    "                  options={'disp': True})\n",
    "ll_R = -result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reject the null hypothesis (p-value: 0.0000)'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ratio_test(ll_U, ll_R, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c: Intercept and time specific alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the model looks as follows:\n",
    "\n",
    "$$\n",
    "V_{nj}=\\alpha_j+\\beta C_{nj}+\\gamma_jT_{nj}\n",
    "$$\n",
    "\n",
    "So, the number of paremeters is $3 + 1 + 4 = 8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of modes\n",
    "modes = ['bike', 'bus', 'car', 'walk']\n",
    "\n",
    "# Reshape the DataFrame\n",
    "rows = []\n",
    "for index, row in commute_data.iterrows():\n",
    "    for mode in modes:\n",
    "        rows.append({\n",
    "            'id': row['id'],\n",
    "            'mode': mode,\n",
    "            'time': row[f'time.{mode}'],\n",
    "            'cost': row[f'cost.{mode}'],\n",
    "            'choice': 1 if row['mode'] == mode else 0\n",
    "        })\n",
    "\n",
    "commute_long_c = pd.DataFrame(rows)\n",
    "\n",
    "for mode in modes:\n",
    "    commute_long_c[f'dummy_{mode}'] = (commute_long_c['mode'] == mode).astype(int)\n",
    "    commute_long_c[f'time_{mode}'] = commute_long_c['time'] * commute_long_c[f'dummy_{mode}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_c(params, data):\n",
    "    # Create a copy of the input DataFrame to avoid modifying the original one\n",
    "    df = data.copy()\n",
    "    X = df[['dummy_bike', 'dummy_bus', 'dummy_car',\n",
    "            'dummy_walk', 'time_bike', 'time_bus', 'time_car', 'time_walk',\n",
    "            'cost']]\n",
    "    N = X.shape[1]\n",
    "    n = len(params)\n",
    "    for i in range(N - n):\n",
    "        params = np.insert(params, 0, 0)\n",
    "        \n",
    "    # Calculating the exponential utility\n",
    "    df['exp_Util'] = np.exp(np.dot(X, params))\n",
    "    # Summing exp_Util for each id\n",
    "    df['sum_exp_Util'] = df.groupby('id')['exp_Util'].transform('sum')\n",
    "    # Probability calculation\n",
    "    df['prob'] = df['exp_Util'] / df['sum_exp_Util']\n",
    "    # Calculating the log-likelihood\n",
    "    loglikelihood_value = np.sum(df['choice'] * np.log(df['prob']))\n",
    "    # Return negative log-likelihood (for minimization)\n",
    "    return -loglikelihood_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 982.356064\n",
      "         Iterations: 22\n",
      "         Function evaluations: 270\n",
      "         Gradient evaluations: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_minimize.py:705: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    }
   ],
   "source": [
    "initial_params_c = np.zeros(8) # alpha_bike, alpha_bus, alpha_car, alpha_walk, beta, gamma\n",
    "result = minimize(loglikelihood_c, \n",
    "                  initial_params_c, \n",
    "                  args=(commute_long_c[['dummy_bike', 'dummy_bus', 'dummy_car', 'dummy_walk',\n",
    "                                      'id', 'choice', 'time_bike', 'time_bus',\n",
    "                                      'time_car', 'time_walk', 'cost']],),\n",
    "                  method='BFGS', \n",
    "                  options={'disp': True})\n",
    "parameters = result.x\n",
    "ll_U = -result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Parameters  Coefficient  Standard Error  Z-statistic  P-value\n",
      "  Bus_intecept       -0.219           0.372       -0.589    0.556\n",
      " Car_intercept        2.746           0.366        7.510    0.000\n",
      "Walk_intercept        2.975           1.083        2.747    0.006\n",
      "     time_bike       -0.289           0.039       -7.488    0.000\n",
      "      time_bus       -0.143           0.040       -3.616    0.000\n",
      "      time_car       -0.405           0.039      -10.436    0.000\n",
      "     time_walk       -0.297           0.043       -6.857    0.000\n",
      "          Cost       -2.604           0.986       -2.640    0.008\n"
     ]
    }
   ],
   "source": [
    "std = np.sqrt(result.hess_inv.diagonal())\n",
    "z_stat = parameters / std\n",
    "p_values = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "summary_table_b = pd.DataFrame({\n",
    "    'Parameters': ['Bus_intecept', 'Car_intercept', 'Walk_intercept',\n",
    "                   'time_bike', 'time_bus',\n",
    "                    'time_car', 'time_walk',\n",
    "                    'Cost'],\n",
    "    'Coefficient': parameters,\n",
    "    'Standard Error': std,\n",
    "    'Z-statistic': z_stat,\n",
    "    'P-value': p_values\n",
    "})\n",
    "print(summary_table_b.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results suggest that, ceteris paribus, driving or walking would be preferred to taking the bus or biking. Also, we can see the heterogeneity in the time coefficients, depending on the alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a likelihood ratio test\n",
    "$$\n",
    "H_0: \\gamma_{bike}=\\gamma_{bus}=\\gamma_{car}=\\gamma_{walk}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params_c_restricted = np.zeros(8) # alpha_bike, alpha_bus, alpha_car, alpha_walk, beta, gamma\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: x[4] - x[5]},\n",
    "               {'type': 'eq', 'fun': lambda x: x[5] - x[6]},\n",
    "               {'type': 'eq', 'fun': lambda x: x[6] - x[7]})\n",
    "result = minimize(loglikelihood_c, \n",
    "                  initial_params_c_restricted, \n",
    "                  args=(commute_long_c[['dummy_bike', 'dummy_bus', 'dummy_car', 'dummy_walk',\n",
    "                                      'id', 'choice', 'time_bike', 'time_bus',\n",
    "                                      'time_car', 'time_walk', 'cost']],),\n",
    "                  method='SLSQP',\n",
    "                  constraints=constraints, \n",
    "                  options={'disp': True})\n",
    "parameters = result.x\n",
    "ll_R = -result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reject the null hypothesis (p-value: 0.0000)'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ratio_test(ll_U, ll_R, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have rejected the null. Therefore, having heterogeneity in the time coefficient of different alternatives is a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Generalized Method of Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get back to the case of a binary logit model. We only have two alternatives, bus or car. The values are as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}&V_{nc}=\\alpha+\\beta C_{nc}+\\gamma_{car}T_{nc}\\\\&V_{nb}=\\gamma_{bus}T_{nb}\\end{aligned}\n",
    "$$\n",
    "\n",
    "So, we have both intercept specific and time specific parameters. We have:\n",
    "$$\n",
    "V_{nc}-V_{nb}=\\alpha+\\beta C_{nc}+\\gamma_{car}T_{nc}-\\gamma_{bus}T_{nb}\n",
    "$$\n",
    "And the probability of choosing to drive is:\n",
    "\n",
    "$$\n",
    "P_{nc}= \\frac{e^{V_{nc}}}{e^{V_{nc}} + e^{V_{nb}}} = \\frac1{1+e^{-(V_{nc}-V_{nb})}}\n",
    "$$\n",
    "\n",
    "Here, we have 4 parameters. Therefore, at least we need 4 moment conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLE, we remember that the optimization problem is:\n",
    "\n",
    "$$\n",
    "\\max \\sum_{n=1}^N \\sum_{i=1}^J y_{n i} \\ln \\left[\\frac{e^{\\beta'x_{ni}}}{\\sum_j e^{\\beta'x_{nj}}}\\right]\n",
    "$$\n",
    "\n",
    "Then, the FOCs look as follows:\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^N\\sum_{i=1}^J\\left(y_{ni}-P_{ni}(x_n,\\beta)\\right)x_{ni}=0\n",
    "$$\n",
    "This indeed can be a moment condition as follows:\n",
    "$$\n",
    "E[\\left(y_{ni}-P_{ni}(x_n,\\beta)\\right)x_{ni}] = 0\n",
    "$$\n",
    "In other words, our data characteristics is orthogonal to the error. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model here, $x_{ni} = \\{1, C_{nc}, T_{nc}, -T_{nb}\\}$. So, we will have four moment conditions and four parameters. So, this model is just-identified using GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_binary = pd.read_csv(address + '\\\\commute_binary.csv')\n",
    "commute_binary['choice'] = (commute_binary['mode'] == 'car').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will setup the full two step GMM from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_fn(params, data):\n",
    "    X = data[['cost.car', 'time.car', 'time.bus']]\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.values\n",
    "    y = data['choice'].values\n",
    "    prob = expit(np.dot(X, params))\n",
    "    # prob = 1/(1 + np.exp(-np.dot(X, params)))\n",
    "    error = y - prob\n",
    "    return error[:, np.newaxis] * X\n",
    "\n",
    "def gmm_obj(params, data, weight):\n",
    "    moments = mm_fn(params, data)\n",
    "    N = len(data)\n",
    "    moments_sum = (np.sum(moments, axis=0) / N)[:, np.newaxis] ## N*4 -> 4*1, sum on axis = 0\n",
    "    obj = np.dot(np.dot(moments_sum.T, weight), moments_sum) / N\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First stage done\n",
      "Inverse of covariance matrix of empirical moments is calculated\n",
      "Second stage done\n",
      "Second stage results\n",
      "[ 2.23326705 -2.07715637 -0.33221545  0.13257431]\n"
     ]
    }
   ],
   "source": [
    "initial_params = np.zeros(4)\n",
    "\n",
    "N = len(commute_binary)\n",
    "\n",
    "weight = np.random.rand(4,4)\n",
    "\n",
    "result = minimize(gmm_obj, initial_params, \n",
    "                  args=(commute_binary, weight,), \n",
    "                  method='Nelder-Mead',\n",
    "                  options={'xatol': 1e-10, 'maxiter': 10000})\n",
    "parameters_first = result.x\n",
    "\n",
    "print(\"First stage done\")\n",
    "#print(\"First stage results\")\n",
    "#print(parameters_first)\n",
    "\n",
    "moments = mm_fn(parameters_first, commute_binary)\n",
    "covariance_matrix = np.cov(moments, rowvar=False)\n",
    "try:\n",
    "    inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "    print(\"Inverse of covariance matrix of empirical moments is calculated\")\n",
    "    result = minimize(gmm_obj, initial_params, \n",
    "                  args=(commute_binary, inv_cov_matrix,), \n",
    "                  method='Nelder-Mead',\n",
    "                  options={'xatol': 1e-10, 'maxiter': 10000})\n",
    "    parameters_second = result.x\n",
    "    value = gmm_obj(parameters_second, commute_binary, inv_cov_matrix)\n",
    "    print(\"Second stage done\")\n",
    "    print(\"Second stage results\")\n",
    "    print(parameters_second)\n",
    "    # print(\"Value of the GMM objective function at the second stage is:\")\n",
    "    # print(value)\n",
    "except np.linalg.LinAlgError:\n",
    "    print('Singular matrix')\n",
    "    print('only results of first stage are available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to find the asymptotic variance of this estimator. \n",
    "\n",
    "$$\n",
    "\n",
    "\\widehat{\\boldsymbol{\\theta}} \\stackrel{a}{\\sim} \\mathcal{N}\\left(\\boldsymbol{\\theta}_0,{Var}(\\widehat{\\boldsymbol{\\theta}})\\right) \\\\\n",
    "\\widehat{Var}(\\widehat{\\boldsymbol{\\theta}})=\\frac{1}{n}\\left(\\widehat{\\boldsymbol{G}}^{\\prime}\\widehat{\\boldsymbol{S}}^{-1}\\widehat{\\boldsymbol{G}}\\right)^{-1} \\\\\\begin{aligned}&\\widehat{\\boldsymbol{G}}=\\frac1n\\sum_{i=1}^n\\left.\\frac{\\partial\\boldsymbol{m}(y_i,\\boldsymbol{x}_i,\\boldsymbol{z}_i,\\boldsymbol{\\theta})}{\\partial\\boldsymbol{\\theta}^{\\prime}}\\right|_{\\theta=\\widehat{\\boldsymbol{\\theta}}}\\\\&\\widehat{\\boldsymbol{S}}=\\frac1n\\sum_{i=1}^n\\boldsymbol{m}(y_i,x_i,z_i,\\widehat{\\theta})\\boldsymbol{m}(y_i,x_i,z_i,\\widehat{\\theta})^{\\prime}\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we write a function to find the first order derivate of moments with respect to parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian_and_sum(params, data):\n",
    "    X = data[['cost.car', 'time.car', 'time.bus']]\n",
    "    X = np.hstack([np.ones((X.shape[0], 1)), X])  # Add intercept term (constant)\n",
    "    y = data['choice'].values\n",
    "    prob = expit(np.dot(X, params))  # Sigmoid function to get probabilities\n",
    "    # Initialize the sum of Jacobians as a zero 4x4 matrix\n",
    "    sum_jacobian = np.zeros((4, 4))\n",
    "    # Loop through each data point\n",
    "    for i in range(len(y)):\n",
    "        xi = X[i]  # 1x4 vector\n",
    "        pi = prob[i]  # scalar\n",
    "        error_i = y[i] - pi  # scalar\n",
    "        # Gradient of the probability with respect to params: pi * (1 - pi) * xi\n",
    "        gradient = pi * (1 - pi) * np.outer(xi, xi)  # 4x4 matrix\n",
    "        # Contribution to the Jacobian from the i-th data point\n",
    "        jacobian_i = -gradient  # 4x4 matrix\n",
    "        # Sum the Jacobian\n",
    "        sum_jacobian += jacobian_i\n",
    "    \n",
    "    return sum_jacobian\n",
    "\n",
    "# Calculate the sum of Jacobians\n",
    "Jacobian = compute_jacobian_and_sum(parameters_second, commute_binary)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = mm_fn(parameters_second, commute_binary)\n",
    "hat_S = np.cov(moments, rowvar=False)\n",
    "hat_S_inv = np.linalg.inv(hat_S)\n",
    "Var_estimator = np.linalg.inv(Jacobian.T @ hat_S_inv @ Jacobian)/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the result of this model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parameters  Coefficient  Standard Error  Z-statistic  P-value\n",
      "Intercept_car        2.233           0.375        5.949    0.000\n",
      "         Cost       -2.077           0.718       -2.892    0.004\n",
      "     Time.car       -0.332           0.038       -8.755    0.000\n",
      "     Time.Bus       -0.133           0.032       -4.150    0.000\n"
     ]
    }
   ],
   "source": [
    "parameters_second[3] = -parameters_second[3]\n",
    "std = np.sqrt(np.diag(Var_estimator))\n",
    "z_stat = parameters_second / std\n",
    "p_values = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "summary_table_gmm_a = pd.DataFrame({\n",
    "    'Parameters': ['Intercept_car', 'Cost', 'Time.car', 'Time.Bus'],\n",
    "    'Coefficient': parameters_second,\n",
    "    'Standard Error': std,\n",
    "    'Z-statistic': z_stat,\n",
    "    'P-value': p_values\n",
    "})\n",
    "print(summary_table_gmm_a.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, ceteris paribus, the positive intercept of car shows that, relatively, students likes to drive than to take the bus. Also, as expected, the marginal utilities of cost and time are negative and significant. Also, the negative MU of time of bus is less than time of car. Therefore, students prefer time on the bus rather than driving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Endogeneity\n",
    "\n",
    "It might be the case that time and cost are endogenous in this model. For example, someone who prefers to drive has chosen to live far away from the destination because they do not mind the extra cost\n",
    "and time spent driving, and a student who enjoys taking the bus is more likely to live close to a\n",
    "bus stop so the bus commute time is less.\n",
    "\n",
    "So, we need instruments for them. We have four other variables we can use here as instruments. price_gas, snowfall, construction, and bus_detour.\n",
    "Price_gas only affects the choice through cost. In other words, fixing the cost, a change in the price of gas would not change the choice variable. Moreover, snowfall, construction and bus_detour only affect time of bus and time of car and then the output variable. Therefore, these variables can be taken as valid instruments.\n",
    "\n",
    "Now, the exogenous terms are:\n",
    "\n",
    "$$\n",
    "Z = \\{z_1 = \\text{intercept}, z_2 = \\text{price-gas}, z_3 = \\text{snowfall}, z_4=\\text{construction},\n",
    "z_5 = \\text{bus-detour}\\}\n",
    "$$\n",
    "\n",
    "Therefore, we have four parameters to estimate (like before), yet, five moment conditions. The moment conditions are:\n",
    "$$\n",
    "E[\\left(y_{ni}-P_{ni}(x_n,\\beta)\\right)z_{ni}] = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_fn_endog(params, data):\n",
    "    Z = data[['price_gas', 'snowfall', 'construction', 'bus_detour']]\n",
    "    Z = sm.add_constant(Z)\n",
    "    X = data[['cost.car', 'time.car', 'time.bus']]\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.values\n",
    "    Z = Z.values\n",
    "    y = data['choice'].values\n",
    "    prob = expit(np.dot(X, params))\n",
    "    # prob = 1/(1 + np.exp(-np.dot(X, params)))\n",
    "    error = y - prob\n",
    "    return error[:, np.newaxis] * Z\n",
    "\n",
    "def gmm_obj_endog(params, data, weight):\n",
    "    moments = mm_fn_endog(params, data)\n",
    "    N = len(data)\n",
    "    moments_sum = (np.sum(moments, axis=0) / N)[:, np.newaxis] ## N*4 -> 4*1, sum on axis = 0\n",
    "    obj = np.dot(np.dot(moments_sum.T, weight), moments_sum) / N\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First stage done\n",
      "Inverse of covariance matrix of empirical moments is calculated\n",
      "Second stage done\n",
      "Second stage results\n",
      "[ 2.91199065 -3.98605088 -0.35094517  0.15029961]\n"
     ]
    }
   ],
   "source": [
    "initial_params = np.zeros(4)\n",
    "\n",
    "N = len(commute_binary)\n",
    "\n",
    "weight = np.eye(5)\n",
    "\n",
    "result = minimize(gmm_obj_endog, initial_params, \n",
    "                  args=(commute_binary, weight,), \n",
    "                  method='Nelder-Mead',\n",
    "                  options={'xatol': 1e-10, 'maxiter': 10000})\n",
    "parameters_first = result.x\n",
    "\n",
    "print(\"First stage done\")\n",
    "#print(\"First stage results\")\n",
    "#print(parameters_first)\n",
    "\n",
    "moments = mm_fn_endog(parameters_first, commute_binary)\n",
    "covariance_matrix = np.cov(moments, rowvar=False)\n",
    "try:\n",
    "    inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "    print(\"Inverse of covariance matrix of empirical moments is calculated\")\n",
    "    result = minimize(gmm_obj_endog, initial_params, \n",
    "                  args=(commute_binary, inv_cov_matrix,), \n",
    "                  method='Nelder-Mead',\n",
    "                  options={'xatol': 1e-10, 'maxiter': 10000})\n",
    "    parameters_second = result.x\n",
    "    print(\"Second stage done\")\n",
    "    print(\"Second stage results\")\n",
    "    print(parameters_second)\n",
    "    # print(\"Value of the GMM objective function at the second stage is:\")\n",
    "    # print(value)\n",
    "except np.linalg.LinAlgError:\n",
    "    print('Singular matrix')\n",
    "    print('only results of first stage are available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian_and_sum_endog(params, data):\n",
    "    Z = data[['price_gas', 'snowfall', 'construction', 'bus_detour']]\n",
    "    Z = np.hstack([np.ones((Z.shape[0], 1)), Z])\n",
    "    X = data[['cost.car', 'time.car', 'time.bus']]\n",
    "    X = np.hstack([np.ones((X.shape[0], 1)), X])  # Add intercept term (constant)\n",
    "    y = data['choice'].values\n",
    "    prob = expit(np.dot(X, params))  # Sigmoid function to get probabilities\n",
    "    # Initialize the sum of Jacobians as a zero 4x4 matrix\n",
    "    sum_jacobian = np.zeros((5, 4))\n",
    "    # Loop through each data point\n",
    "    for i in range(len(y)):\n",
    "        zi = Z[i]  # 1x5 vector\n",
    "        xi = X[i] # 1x4 vector\n",
    "        pi = prob[i]  # scalar\n",
    "        error_i = y[i] - pi  # scalar\n",
    "        # Gradient of the probability with respect to params: pi * (1 - pi) * xi\n",
    "        gradient = pi * (1 - pi) * np.outer(zi, xi)  # 5x4 matrix\n",
    "        # Contribution to the Jacobian from the i-th data point\n",
    "        jacobian_i = -gradient  # 4x4 matrix\n",
    "        # Sum the Jacobian\n",
    "        sum_jacobian += jacobian_i\n",
    "    \n",
    "    return sum_jacobian\n",
    "\n",
    "# Calculate the sum of Jacobians\n",
    "Jacobian = compute_jacobian_and_sum_endog(parameters_second, commute_binary)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = mm_fn_endog(parameters_second, commute_binary)\n",
    "hat_S = np.cov(moments, rowvar=False)\n",
    "hat_S_inv = np.linalg.inv(hat_S)\n",
    "Var_estimator = np.linalg.inv(Jacobian.T @ hat_S_inv @ Jacobian)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parameters  Coefficient  Standard Error  Z-statistic  P-value\n",
      "Intercept_car        2.912           3.813        0.764    0.445\n",
      "         Cost       -3.986           8.057       -0.495    0.621\n",
      "     Time.car       -0.351           0.123       -2.855    0.004\n",
      "     Time.Bus       -0.150           0.053       -2.859    0.004\n"
     ]
    }
   ],
   "source": [
    "parameters_second[3] = -parameters_second[3]\n",
    "std = np.sqrt(np.diag(Var_estimator))\n",
    "z_stat = parameters_second / std\n",
    "p_values = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "summary_table_gmm_a = pd.DataFrame({\n",
    "    'Parameters': ['Intercept_car', 'Cost', 'Time.car', 'Time.Bus'],\n",
    "    'Coefficient': parameters_second,\n",
    "    'Standard Error': std,\n",
    "    'Z-statistic': z_stat,\n",
    "    'P-value': p_values\n",
    "})\n",
    "print(summary_table_gmm_a.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estimates are roughly the same as those in the previous model. However,\n",
    "the intercept and cost parameters now have much larger standard errors, rendering those\n",
    "parameters not statistically significant. Using instruments can reduce the precision of our\n",
    "parameter estimates, especially if they are not sufficiently correlated with the relevant variables,\n",
    "which may be the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overidentification test\n",
    "\n",
    "As the number of parameters is less than moments, we can run this test to see if empirical moments are actually close enough to zero. \n",
    "\n",
    "$$\n",
    "OIR=\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\boldsymbol{m}(y_{i},\\boldsymbol{x}_{i},\\boldsymbol{z}_{i},\\widehat{\\boldsymbol{\\theta}})\\right]^{\\prime}\\widetilde{\\boldsymbol{S}}^{-1}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\boldsymbol{m}(y_{i},\\boldsymbol{x}_{i},\\boldsymbol{z}_{i},\\widehat{\\boldsymbol{\\theta}})\\right] \\\\ OIR\\overset{a}{\\operatorname*{\\sim}}\\chi^2(L-K)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to reject the null hypothesis (p-value: 0.3703)\n"
     ]
    }
   ],
   "source": [
    "OIR = gmm_obj_endog(parameters_second, commute_binary, hat_S_inv)[0,0]*N\n",
    "p_value = 1 - chi2.cdf(OIR, 1)\n",
    "if p_value < 0.01:\n",
    "    result = f'Reject the null hypothesis (p-value: {p_value:.4f})'\n",
    "else:\n",
    "    result = f'Fail to reject the null hypothesis (p-value: {p_value:.4f})'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we failed to reject the null. So we conclude that all\n",
    "empirical moments are sufficiently close to zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
